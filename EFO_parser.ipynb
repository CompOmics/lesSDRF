{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting streamlit-tree-select\n",
      "  Downloading streamlit_tree_select-0.0.5-py3-none-any.whl (1.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: streamlit>=0.63 in /home/compomics/miniconda3/envs/reprocessing/lib/python3.11/site-packages (from streamlit-tree-select) (1.23.1)\n",
      "Requirement already satisfied: altair<6,>=4.0 in /home/compomics/miniconda3/envs/reprocessing/lib/python3.11/site-packages (from streamlit>=0.63->streamlit-tree-select) (5.0.1)\n",
      "Requirement already satisfied: blinker<2,>=1.0.0 in /home/compomics/miniconda3/envs/reprocessing/lib/python3.11/site-packages (from streamlit>=0.63->streamlit-tree-select) (1.6.2)\n",
      "Requirement already satisfied: cachetools<6,>=4.0 in /home/compomics/miniconda3/envs/reprocessing/lib/python3.11/site-packages (from streamlit>=0.63->streamlit-tree-select) (5.3.1)\n",
      "Requirement already satisfied: click<9,>=7.0 in /home/compomics/miniconda3/envs/reprocessing/lib/python3.11/site-packages (from streamlit>=0.63->streamlit-tree-select) (8.1.3)\n",
      "Requirement already satisfied: importlib-metadata<7,>=1.4 in /home/compomics/miniconda3/envs/reprocessing/lib/python3.11/site-packages (from streamlit>=0.63->streamlit-tree-select) (6.7.0)\n",
      "Requirement already satisfied: numpy<2,>=1 in /home/compomics/miniconda3/envs/reprocessing/lib/python3.11/site-packages (from streamlit>=0.63->streamlit-tree-select) (1.25.0)\n",
      "Requirement already satisfied: packaging<24,>=14.1 in /home/compomics/miniconda3/envs/reprocessing/lib/python3.11/site-packages (from streamlit>=0.63->streamlit-tree-select) (23.1)\n",
      "Requirement already satisfied: pandas<3,>=0.25 in /home/compomics/miniconda3/envs/reprocessing/lib/python3.11/site-packages (from streamlit>=0.63->streamlit-tree-select) (2.0.2)\n",
      "Requirement already satisfied: pillow<10,>=6.2.0 in /home/compomics/miniconda3/envs/reprocessing/lib/python3.11/site-packages (from streamlit>=0.63->streamlit-tree-select) (9.5.0)\n",
      "Requirement already satisfied: protobuf<5,>=3.20 in /home/compomics/miniconda3/envs/reprocessing/lib/python3.11/site-packages (from streamlit>=0.63->streamlit-tree-select) (4.23.3)\n",
      "Requirement already satisfied: pyarrow>=4.0 in /home/compomics/miniconda3/envs/reprocessing/lib/python3.11/site-packages (from streamlit>=0.63->streamlit-tree-select) (12.0.1)\n",
      "Requirement already satisfied: pympler<2,>=0.9 in /home/compomics/miniconda3/envs/reprocessing/lib/python3.11/site-packages (from streamlit>=0.63->streamlit-tree-select) (1.0.1)\n",
      "Requirement already satisfied: python-dateutil<3,>=2 in /home/compomics/miniconda3/envs/reprocessing/lib/python3.11/site-packages (from streamlit>=0.63->streamlit-tree-select) (2.8.2)\n",
      "Requirement already satisfied: requests<3,>=2.4 in /home/compomics/miniconda3/envs/reprocessing/lib/python3.11/site-packages (from streamlit>=0.63->streamlit-tree-select) (2.31.0)\n",
      "Requirement already satisfied: rich<14,>=10.11.0 in /home/compomics/miniconda3/envs/reprocessing/lib/python3.11/site-packages (from streamlit>=0.63->streamlit-tree-select) (13.4.2)\n",
      "Requirement already satisfied: tenacity<9,>=8.0.0 in /home/compomics/miniconda3/envs/reprocessing/lib/python3.11/site-packages (from streamlit>=0.63->streamlit-tree-select) (8.2.2)\n",
      "Requirement already satisfied: toml<2 in /home/compomics/miniconda3/envs/reprocessing/lib/python3.11/site-packages (from streamlit>=0.63->streamlit-tree-select) (0.10.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.0.1 in /home/compomics/miniconda3/envs/reprocessing/lib/python3.11/site-packages (from streamlit>=0.63->streamlit-tree-select) (4.6.3)\n",
      "Requirement already satisfied: tzlocal<5,>=1.1 in /home/compomics/miniconda3/envs/reprocessing/lib/python3.11/site-packages (from streamlit>=0.63->streamlit-tree-select) (4.3)\n",
      "Requirement already satisfied: validators<1,>=0.2 in /home/compomics/miniconda3/envs/reprocessing/lib/python3.11/site-packages (from streamlit>=0.63->streamlit-tree-select) (0.20.0)\n",
      "Requirement already satisfied: gitpython!=3.1.19,<4,>=3 in /home/compomics/miniconda3/envs/reprocessing/lib/python3.11/site-packages (from streamlit>=0.63->streamlit-tree-select) (3.1.31)\n",
      "Requirement already satisfied: pydeck<1,>=0.1.dev5 in /home/compomics/miniconda3/envs/reprocessing/lib/python3.11/site-packages (from streamlit>=0.63->streamlit-tree-select) (0.8.1b0)\n",
      "Requirement already satisfied: tornado<7,>=6.0.3 in /home/compomics/miniconda3/envs/reprocessing/lib/python3.11/site-packages (from streamlit>=0.63->streamlit-tree-select) (6.3.2)\n",
      "Requirement already satisfied: watchdog in /home/compomics/miniconda3/envs/reprocessing/lib/python3.11/site-packages (from streamlit>=0.63->streamlit-tree-select) (3.0.0)\n",
      "Requirement already satisfied: jinja2 in /home/compomics/miniconda3/envs/reprocessing/lib/python3.11/site-packages (from altair<6,>=4.0->streamlit>=0.63->streamlit-tree-select) (3.1.2)\n",
      "Requirement already satisfied: jsonschema>=3.0 in /home/compomics/miniconda3/envs/reprocessing/lib/python3.11/site-packages (from altair<6,>=4.0->streamlit>=0.63->streamlit-tree-select) (4.17.3)\n",
      "Requirement already satisfied: toolz in /home/compomics/miniconda3/envs/reprocessing/lib/python3.11/site-packages (from altair<6,>=4.0->streamlit>=0.63->streamlit-tree-select) (0.12.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /home/compomics/miniconda3/envs/reprocessing/lib/python3.11/site-packages (from gitpython!=3.1.19,<4,>=3->streamlit>=0.63->streamlit-tree-select) (4.0.10)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/compomics/miniconda3/envs/reprocessing/lib/python3.11/site-packages (from importlib-metadata<7,>=1.4->streamlit>=0.63->streamlit-tree-select) (3.15.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/compomics/miniconda3/envs/reprocessing/lib/python3.11/site-packages (from pandas<3,>=0.25->streamlit>=0.63->streamlit-tree-select) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/compomics/miniconda3/envs/reprocessing/lib/python3.11/site-packages (from pandas<3,>=0.25->streamlit>=0.63->streamlit-tree-select) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /home/compomics/miniconda3/envs/reprocessing/lib/python3.11/site-packages (from python-dateutil<3,>=2->streamlit>=0.63->streamlit-tree-select) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/compomics/miniconda3/envs/reprocessing/lib/python3.11/site-packages (from requests<3,>=2.4->streamlit>=0.63->streamlit-tree-select) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/compomics/miniconda3/envs/reprocessing/lib/python3.11/site-packages (from requests<3,>=2.4->streamlit>=0.63->streamlit-tree-select) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/compomics/miniconda3/envs/reprocessing/lib/python3.11/site-packages (from requests<3,>=2.4->streamlit>=0.63->streamlit-tree-select) (2.0.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/compomics/miniconda3/envs/reprocessing/lib/python3.11/site-packages (from requests<3,>=2.4->streamlit>=0.63->streamlit-tree-select) (2023.5.7)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/compomics/miniconda3/envs/reprocessing/lib/python3.11/site-packages (from rich<14,>=10.11.0->streamlit>=0.63->streamlit-tree-select) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/compomics/miniconda3/envs/reprocessing/lib/python3.11/site-packages (from rich<14,>=10.11.0->streamlit>=0.63->streamlit-tree-select) (2.15.1)\n",
      "Requirement already satisfied: pytz-deprecation-shim in /home/compomics/miniconda3/envs/reprocessing/lib/python3.11/site-packages (from tzlocal<5,>=1.1->streamlit>=0.63->streamlit-tree-select) (0.1.0.post0)\n",
      "Requirement already satisfied: decorator>=3.4.0 in /home/compomics/miniconda3/envs/reprocessing/lib/python3.11/site-packages (from validators<1,>=0.2->streamlit>=0.63->streamlit-tree-select) (5.1.1)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /home/compomics/miniconda3/envs/reprocessing/lib/python3.11/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3->streamlit>=0.63->streamlit-tree-select) (5.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/compomics/miniconda3/envs/reprocessing/lib/python3.11/site-packages (from jinja2->altair<6,>=4.0->streamlit>=0.63->streamlit-tree-select) (2.1.3)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /home/compomics/miniconda3/envs/reprocessing/lib/python3.11/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit>=0.63->streamlit-tree-select) (23.1.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /home/compomics/miniconda3/envs/reprocessing/lib/python3.11/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit>=0.63->streamlit-tree-select) (0.19.3)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/compomics/miniconda3/envs/reprocessing/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich<14,>=10.11.0->streamlit>=0.63->streamlit-tree-select) (0.1.2)\n",
      "Installing collected packages: streamlit-tree-select\n",
      "Successfully installed streamlit-tree-select-0.0.5\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install streamlit-tree-select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import rdflib\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from rdflib import Graph, Namespace, RDFS, RDF, OWL\n",
    "from owlready2 import get_ontology\n",
    "from owlready2 import *\n",
    "from rdflib import Graph, Namespace, RDFS\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import pickle\n",
    "import ParsingModule\n",
    "from ParsingModule import store_as_gzipped_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_children(ontology, term_id, term_label, d, nodes_dict=None, data=None):\n",
    "    if nodes_dict is None:  # load the json file only once\n",
    "        with open(ontology) as f:\n",
    "            data = json.load(f)\n",
    "        nodes_dict = {node[\"id\"]: node[\"lbl\"] for node in data[\"graphs\"][0][\"nodes\"] if all(key in node for key in ['id', 'lbl'])}\n",
    "\n",
    "    if term_id not in nodes_dict:\n",
    "        return f\"{term_id} node not in ontology\" # node not found in ontology, return early\n",
    "\n",
    "    if term_label not in d: \n",
    "        d[term_label] = {}  # add the parent to the dictionary\n",
    "\n",
    "    for term in data[\"graphs\"][0][\"edges\"]: # iterate through the edges\n",
    "        if (term[\"obj\"] == term_id) and (term[\"pred\"] in [\"http://purl.obolibrary.org/obo/BFO_0000050\", 'is_a']):\n",
    "            parent = term[\"sub\"]\n",
    "            if parent == \"http://purl.obolibrary.org/obo/MONDO_0011876\":\n",
    "                continue    # skip MONDO_0011876\n",
    "            parent_label = nodes_dict.get(parent)\n",
    "            if parent_label is not None:\n",
    "                if parent_label in d:\n",
    "                    d[term_label][parent_label] = d[parent_label]\n",
    "                    del d[parent_label]\n",
    "                else:\n",
    "                    d[term_label][parent_label] = {}\n",
    "                get_children(ontology, parent, parent_label, d[term_label], nodes_dict, data)\n",
    "\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(d):\n",
    "    items = []\n",
    "    for k, v in d.items(): # iterate through the dictionary\n",
    "        items.append(k) # add the key to the list\n",
    "        if isinstance(v, dict):# if the value is a dictionary, call the function recursively\n",
    "            items.extend(flatten(v))\n",
    "        else:\n",
    "            items.append(v)\n",
    "    return items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_nested_dict_to_tree(d, parent_label=None, parent_value=None):\n",
    "    result = []\n",
    "    for key, value in d.items():\n",
    "        label = key\n",
    "        if parent_label:\n",
    "            label = f\"{parent_label} , {key}\"\n",
    "        children = []\n",
    "        if value:\n",
    "            children = transform_nested_dict_to_tree(value, label, key)\n",
    "        if children:\n",
    "            result.append({\"label\": key, \"value\": label, \"children\": children})\n",
    "        else:\n",
    "            result.append({\"label\": key, \"value\": label})\n",
    "    return result"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JSON file EFO"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### organism part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "d=dict()\n",
    "orgpart_dict = get_children('/home/compomics/git/Publication/lesSDRF/ontology/efo.json', \"http://www.ebi.ac.uk/efo/EFO_0000635\",'organism part', d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "orgpart_dict = orgpart_dict['organism part']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "orgpart_dict['Not available'] = {}\n",
    "orgpart_dict['Not applicable'] = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['anatomical entity', 'anatomy basic component', 'Not available', 'Not applicable'])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orgpart_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['umbilical cord', 'seminal fluid', 'primordium', 'abdominal cavity', 'peritoneal cavity', 'sensory system', 'bodily fluid', 'nasal cavity', 'retroperitoneal space', 'mushroom body', 'saliva', 'decidua basalis', 'meningeal cluster', 'vasculature', 'upper urinary tract', 'embryonic structure', 'head capsule', 'endocrine system', 'renal pelvis/ureter', 'tegmentum', 'venom', 'excreta', 'anatomical structure', 'immune system', 'mediastinum', 'early telencephalic vesicle'])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orgpart_dict['anatomical entity'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the dictionary as a pickle\n",
    "with open('orgpart_dict.pickle', 'wb') as handle:\n",
    "    pickle.dump(orgpart_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/compomics/git/Publication/lesSDRF/data/organismpart_dict.pickle'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m#load pickle into dict\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m(\u001b[39m'\u001b[39;49m\u001b[39m/home/compomics/git/Publication/lesSDRF/data/organismpart_dict.pickle\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m handle:\n\u001b[1;32m      3\u001b[0m     orgpart_dict \u001b[39m=\u001b[39m pickle\u001b[39m.\u001b[39mload(handle)\n\u001b[1;32m      4\u001b[0m \u001b[39m# make streamlit tree\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/reprocessing/lib/python3.11/site-packages/IPython/core/interactiveshell.py:284\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[39mif\u001b[39;00m file \u001b[39min\u001b[39;00m {\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m}:\n\u001b[1;32m    278\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    279\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mIPython won\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt let you open fd=\u001b[39m\u001b[39m{\u001b[39;00mfile\u001b[39m}\u001b[39;00m\u001b[39m by default \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    280\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    281\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39myou can use builtins\u001b[39m\u001b[39m'\u001b[39m\u001b[39m open.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    282\u001b[0m     )\n\u001b[0;32m--> 284\u001b[0m \u001b[39mreturn\u001b[39;00m io_open(file, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/compomics/git/Publication/lesSDRF/data/organismpart_dict.pickle'"
     ]
    }
   ],
   "source": [
    "#load pickle into dict\n",
    "with open('/home/compomics/git/Publication/lesSDRF/data/organismpart_dict.pickle', 'rb') as handle:\n",
    "    orgpart_dict = pickle.load(handle)\n",
    "# make streamlit tree\n",
    "organismpart_nodes = transform_nested_dict_to_tree(orgpart_dict['organism part'])\n",
    "with open('/home/compomics/git/Publication/lesSDRF/data/organismpart_nodes.pickle', 'wb') as handle:\n",
    "    pickle.dump(organismpart_nodes, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "# flatten into a list of elements\n",
    "all_organismpart_elements = flatten(orgpart_dict['organism part'])\n",
    "with open('/home/compomics/git/Publication/lesSDRF/data/all_organismpart_elements.pickle', 'wb') as handle:\n",
    "    pickle.dump(all_organismpart_elements, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('C:\\\\Users\\\\tinec\\\\OneDrive - UGent\\\\git\\\\SDRF_GUI\\\\onto_dicts\\\\all_organismpart_elements.pickle', 'rb') as handle:\n",
    "    x = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Stored all_organism_part_dict_elements as gzipped json'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make streamlit tree\n",
    "orgpart_nodes = transform_nested_dict_to_tree(orgpart_dict)\n",
    "all_orgpart_elements = flatten(orgpart_dict)\n",
    "store_as_gzipped_json(orgpart_dict, \"organism_part_dict\")\n",
    "store_as_gzipped_json(orgpart_nodes, \"organism_part_dict_nodes\")\n",
    "store_as_gzipped_json(all_orgpart_elements, \"all_organism_part_dict_elements\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26865"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_organismpart_elements)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### for cell types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "d=dict()\n",
    "celltype_dict = get_children('C:\\\\Users\\\\tinec\\\\OneDrive - UGent\\\\git\\\\SDRF_GUI\\\\ontology\\\\efo.json', \"http://www.ebi.ac.uk/efo/EFO_0000324\",'cell type', d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "celltype_dict = celltype_dict['cell type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "celltype_dict['Not available'] = {}\n",
    "celltype_dict['Not applicable'] = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['epithelial cell', 'embryonic cell (metazoa)', 'photosynthetic cell', 'mouse erythroleukemia cell', 'clear cell', 'somatic cell', 'fungal cell', 'prokaryotic cell', 'immortal cell line cell', 'neoplastic cell', 'integumental cell', 'diploid cell', 'lung cancer cell', 'follicular dendritic cell', 'mantle cell', 'glial brain cell', 'merkel cell', 'mouse neural progenitor cell', 'electrically active cell', 'ligament cell', 'bone marrow cell', 'disease cell type', 'inferred cell type', 'plant cell', 'secretory cell', 'stem cell', 'pancreatic cell', 'nervous system cell', 'infected cell', 'non-terminally differentiated cell', 'experimental cell', 'musculo-skeletal system cell', 'reproductive system cell', 'Not available'])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "celltype_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Stored all_celltype_elements as gzipped json'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "celltype_nodes = transform_nested_dict_to_tree(celltype_dict)\n",
    "all_celltype_elements = flatten(celltype_dict)\n",
    "store_as_gzipped_json(celltype_dict, \"cell_type_dict\")\n",
    "store_as_gzipped_json(celltype_nodes, \"cell_type_nodes\")\n",
    "store_as_gzipped_json(all_celltype_elements, \"all_cell_type_elements\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### for disease  'characteristics[disease]',==> ontology, EFO:0000408"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "d=dict()\n",
    "disease_dict = get_children('C:\\\\Users\\\\tinec\\\\OneDrive - UGent\\\\git\\\\SDRF_GUI\\\\ontology\\\\efo.json', \"http://www.ebi.ac.uk/efo/EFO_0000408\",'disease', d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(disease_dict['disease'].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "disease_dict['normal'] = {}\n",
    "disease_dict['Not available'] = {}\n",
    "disease_dict['Not applicable'] = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['disease', 'normal', 'Not available'])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disease_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make streamlit tree\n",
    "disease_nodes = transform_nested_dict_to_tree(disease_dict)\n",
    "all_disease_elements = flatten(disease_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Stored all_disease_elements as gzipped json'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store_as_gzipped_json(disease_dict, \"disease_dict\")\n",
    "store_as_gzipped_json(disease_nodes, \"disease_nodes\")\n",
    "store_as_gzipped_json(all_disease_elements, \"all_disease_elements\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### for developmental stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "d=dict()\n",
    "develop_dict = get_children('C:\\\\Users\\\\tinec\\\\OneDrive - UGent\\\\git\\\\SDRF_GUI\\\\ontology\\\\efo.json', \"http://www.ebi.ac.uk/efo/EFO_0000399\",'developmental stage', d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "develop_dict = develop_dict['developmental stage']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "develop_dict['Not available'] = {}\n",
    "develop_dict['Not applicable'] = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Stored all_developmental_stage_elements as gzipped json'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "developmental_stage_nodes = transform_nested_dict_to_tree(develop_dict)\n",
    "all_developmental_stage_elements = flatten(develop_dict)\n",
    "store_as_gzipped_json(develop_dict, \"developmental_stage_dict\")\n",
    "store_as_gzipped_json(developmental_stage_nodes, \"developmental_stage_nodes\")\n",
    "store_as_gzipped_json(all_developmental_stage_elements, \"all_developmental_stage_elements\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## for organism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "d=dict()\n",
    "org_dict = get_children('C:\\\\Users\\\\tinec\\\\OneDrive - UGent\\\\git\\\\SDRF_GUI\\\\ontology\\\\efo.json', \"http://purl.obolibrary.org/obo/OBI_0100026\",'organism', d)\n",
    "org_dict = org_dict['organism']\n",
    "org_dict['Not available'] = {}\n",
    "org_dict['Not applicable'] = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Stored all_organism_elements as gzipped json'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make streamlit tree\n",
    "org_nodes = transform_nested_dict_to_tree(org_dict)\n",
    "all_org_elements = flatten(org_dict)\n",
    "store_as_gzipped_json(org_dict, \"organism_dict\")\n",
    "store_as_gzipped_json(org_nodes, \"organism_nodes\")\n",
    "store_as_gzipped_json(all_org_elements, \"all_organism_elements\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the dictionary as a pickle\n",
    "\n",
    "with open('org_dict.pickle', 'wb') as handle:\n",
    "    pickle.dump(org_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## for ancestry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d=dict()\n",
    "ancestry_dict = get_children('C:\\\\Users\\\\tinec\\\\OneDrive - UGent\\\\git\\\\SDRF_GUI\\\\ontology\\\\efo.json', \"http://purl.obolibrary.org/obo/HANCESTRO_0004\",'ancestry category', d)\n",
    "len(ancestry_dict['ancestry category'].keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the dictionary as a pickle\n",
    "\n",
    "with open('ancestry_dict.pickle', 'wb') as handle:\n",
    "    pickle.dump(ancestry_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "ancestry_nodes = transform_nested_dict_to_tree(ancestry_dict['ancestry category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('ancestry_nodes.pickle', 'wb') as handle:\n",
    "    pickle.dump(ancestry_nodes, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ancestry_elements = flatten(ancestry_dict['ancestry category'])\n",
    "with open('all_ancestry_elements.pickle', 'wb') as handle:\n",
    "    pickle.dump(all_ancestry_elements, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load pickle into dict\n",
    "with open('C:\\\\Users\\\\tinec\\\\OneDrive - UGent\\\\git\\\\SDRF_GUI\\\\onto_dicts\\\\ancestry_dict.pickle', 'rb') as handle:\n",
    "    ancestry_dict = pickle.load(handle)\n",
    "# make streamlit tree\n",
    "develop_nodes = transform_nested_dict_to_tree(ancestry_dict)\n",
    "with open('C:\\\\Users\\\\tinec\\\\OneDrive - UGent\\\\git\\\\SDRF_GUI\\\\onto_dicts\\\\ancestry_nodes.pickle', 'wb') as handle:\n",
    "    pickle.dump(develop_nodes, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "# flatten into a list of elements\n",
    "all_develop_elements = flatten(ancestry_dict)\n",
    "with open('C:\\\\Users\\\\tinec\\\\OneDrive - UGent\\\\git\\\\SDRF_GUI\\\\onto_dicts\\\\all_ancestry_elements.pickle', 'wb') as handle:\n",
    "    pickle.dump(all_celltype_elements, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## for cell line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "d=dict()\n",
    "cell_dict = get_children('C:\\\\Users\\\\tinec\\\\OneDrive - UGent\\\\git\\\\SDRF_GUI\\\\ontology\\\\efo.json', \"http://purl.obolibrary.org/obo/CL_0000000\",'cell', d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_dict = cell_dict['cell']\n",
    "cell_dict['Not available'] = {}\n",
    "cell_dict['Not applicable'] = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_nodes = transform_nested_dict_to_tree(cell_dict)\n",
    "all_cell_elements = flatten(cell_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Stored all_cell_line_elements as gzipped json'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make streamlit tree\n",
    "cell_nodes = transform_nested_dict_to_tree(cell_dict)\n",
    "all_cell_elements = flatten(cell_dict)\n",
    "store_as_gzipped_json(cell_dict, \"cell_line_dict\")\n",
    "store_as_gzipped_json(cell_nodes, \"cell_line_nodes\")\n",
    "store_as_gzipped_json(all_cell_elements, \"all_cell_line_elements\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## for enrichment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "d=dict()\n",
    "enrichment_dict = get_children('C:\\\\Users\\\\tinec\\\\OneDrive - UGent\\\\git\\\\SDRF_GUI\\\\ontology\\\\efo.json', \"http://www.ebi.ac.uk/efo/EFO_0009090\",'enrichment process', d)\n",
    "enrichment_dict['Not available'] = {}\n",
    "enrichment_dict['Not applicable'] = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Stored all_enrichment_elements as gzipped json'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make streamlit tree\n",
    "enrichment_nodes = transform_nested_dict_to_tree(enrichment_dict)\n",
    "all_enrichment_elements = flatten(enrichment_dict)\n",
    "store_as_gzipped_json(enrichment_dict, \"enrichment_dict\")\n",
    "store_as_gzipped_json(enrichment_nodes, \"enrichment_nodes\")\n",
    "store_as_gzipped_json(all_enrichment_elements, \"all_enrichment_elements\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['isolation of cell population', 'cell size selection', 'density gradient centrifugation', 'magnetic affinity cell sorting'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enrichment_dict['enrichment process']['sample enrichment'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "enrichment_nodes = transform_nested_dict_to_tree(enrichment_dict)\n",
    "all_enrichment_elements = flatten(enrichment_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save dict as pickle\n",
    "with open('C:\\\\Users\\\\tinec\\\\OneDrive - UGent\\\\git\\\\SDRF_GUI\\\\onto_dicts\\\\enrichment_dict.pickle', 'wb') as handle:\n",
    "    pickle.dump(enrichment_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "# make streamlit tree\n",
    "with open('C:\\\\Users\\\\tinec\\\\OneDrive - UGent\\\\git\\\\SDRF_GUI\\\\onto_dicts\\\\enrichment_nodes.pickle', 'wb') as handle:\n",
    "    pickle.dump(enrichment_nodes, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "# flatten into a list of elements\n",
    "with open('C:\\\\Users\\\\tinec\\\\OneDrive - UGent\\\\git\\\\SDRF_GUI\\\\onto_dicts\\\\all_enrichment_elements.pickle', 'wb') as handle:\n",
    "    pickle.dump(all_enrichment_elements, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sdrf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "22ea4e8e4bc62f1f2c468860a17a62e47bb896f26c043965a0be0ae51df573cc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
